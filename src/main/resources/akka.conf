include "serialization.conf"
include "clustering.conf"
include "kafka.conf"
include "http.conf"

kafka.brokers = "10.0.0.3:9092"
kafka.brokers = ${?KAFKA_BROKERS_LIST}

akka {
  coordinated-shutdown.exit-jvm = on
  actor {
    provider = "cluster"
    deployment {
      /node/processorRouter {
        router = round-robin-group
        routees.paths = ["/user/node/processor"]
        cluster {
          enabled = on
          allow-local-routees = on
        }
      }
    }
    warn-about-java-serializer-usage = on
    allow-java-serialization = off

    # TODO use: Avro - Protobuff - Thrift
    serializers {
      kryo = "com.twitter.chill.akka.AkkaSerializer"
    }
    serialization-bindings {
      "java.io.Serializable" = kryo
      "java.lang.Throwable" = kryo
    }
    debug {
      lifecycle = off
      receive = off
    }
  }

  test {
    single-expect-default = 10s
  }

  remote {
    log-remote-lifecycle-events = on # this could be turned off

    artery {
      enabled = on
      transport = tcp
      canonical.hostname = ${clustering.ip}
      canonical.port = ${clustering.port}
    }
  }

  cluster {
    log-info = off
    use-dispatcher = cluster-dispatcher
    min-nr-of-members = 1

    failure-detector {
      # implementation-class = "akka.remote.PhiAccrualFailureDetector"
      heartbeat-interval = 5 s
      threshold = 12.0
      max-sample-size = 1000
      min-std-deviation = 400 ms
      acceptable-heartbeat-pause = 11 s
      monitored-by-nr-of-members = 3
      expected-response-after = 2 s
    }

    auto-discovery = off
    seed-nodes = []
    seed-nodes = ${?SEED_NODES}
    seed-nodes = ["akka://"${clustering.cluster.name}"@"${clustering.seed-ip}":"${clustering.seed-port}]
    shutdown-after-unsuccessful-join-seed-nodes = 30s
  }

  # SBR
  cluster.downing-provider-class = "tanukki.akka.cluster.autodown.MajorityLeaderAutoDowning"
  custom-downing {
    stable-after = 10s

    majority-leader-auto-downing {
      majority-member-role = ""
      down-if-in-minority = true
      shutdown-actor-system-on-resolution = true
    }
  }

  io.dns.resolver = async-dns

  management {
    http {
      hostname = "localhost"
      hostname = ${?HOSTNAME}
      bind-hostname = "0.0.0.0"
      port = 8558
      bind-port = 8558
    }
    cluster.bootstrap {
      new-cluster-enabled = on
      contact-point-discovery {
        port-name = "management"
        protocol = "tcp"
        service-name = "application-dns-internal"
        discovery-method = akka-dns
      }
    }
  }

  loglevel = "INFO"
  loglevel = ${?LOG_LEVEL}
  # By default messages sent to dead letters are logged at info level for the sake of caution
  # After a few messages this logging is turned off, to avoid flooding the logs.
  log-dead-letters = 10 # adjust how many dead letters are logged
  log-dead-letters-during-shutdown = on

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  # filter the log events using the backend configuration logback.xml before they are published to the event bus.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  logger-startup-timeout = 15s
}

cluster-dispatcher {
    type = "Dispatcher"
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 4
    }
}